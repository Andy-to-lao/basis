一、 点云都是连续的，图像是离散的
二、 根据lidar不同的特征表达方式[1]，可以将目标检测方法分成以下4种：基于BEV（bird’s eye view）的目标检测方法，基于camera view的目标检测方法，
     基于point-wise feature的目标检测方法，基于融合特征的目标检测方法。
三、 根据激光雷达的成像原理，可以有两种离散化方式，一种基于旋转平面（即激光坐标系下的xy坐标平面）离散化，可以得到BEV（bird‘s eye view）图；
    另一种在垂直方向离散化（即z轴），可以得到Camera view的图。
四、 BEV:BEV图由激光雷达点云在XY坐标平面离散化后投影得到，其中需要人为规定离散化时的分辨率，即点云空间多大的长方体范围（Δl*Δw*Δh）对应离散化后的图像的
     一个像素点（或一组特征向量），如点云20cm*20cm*Δh的长方体空间，对应离散化后的图像的一个像素点。根据长方体空间中点云点特征表达方式不同可以分为
     hand-crafted feature、voxel-feature；
     基于bev的目标检测方法顾名思义是使用bev作为点云特征的表达，其检测流程包括3个部分：bev generator，network backbone， detection head。
     1.（点云的特征表达）在bev generator中，需要根据Δl*Δw*Δh来生成最后L*W*H大小的bev特征图，该特征图是network backbone特征提取网络的输入；
     2.（特征提取主题结构，包含restnet 和 VGG）网络结构的设计需要兼顾性能和效果，一般都是在现有比较大且性能比较好的网络结构基础上进行修改，
       以voxelnet[3]和pointpillar[2]为例；
     3. (检测网络输出，包含目标类别，位置，大小，姿态和速度预测)detection head包括两个任务，即：目标分类与目标定位，分成anchor base的方法和
       anchor free的方法。
     总结：该方法在目前的自动驾驶的3D目标检测方案中应用较广。
五、 Camera view：在这种离散化方式中，激光雷达的垂直分辨率（线数）和水平分辨率（旋转角分辨率）是两个重要的可以依据的参数，
    分别对应了离散化后的图像的高和宽。
      基于cameraview的目标检测方法顾名思义是使用camera view作为点云特征的表达，检测流程包含3个部分：
      camera view generator、network backbone和detection head
      1.camera view generator camera view图是将每圈激光线拉成直线再按行累积而成，因此也称为range view，其中投影图的高为激光线数，
      宽为lidar扫描一圈的点数；
      2.network backbone 网络结构的设计要依据任务需求，基于camera view的目标检测方法，多是以分割任务为主，因此网络结构大都是encode+decode结构
      3.基于camera view的目标检测方法有两种输出方式表达，一种是纯分割区域，另一种是分割与检测框。
        纯分割的输出是基于camera view的模型最直接、最好的一种输出；
        分割任务对于基于camera view的模型相对简单，但是检测框的回归并不容易。
     根据激光雷达的硬件配置，每条激光线都有固定的垂直方向的角度θ，通过计算θ便可以得到某个点云点对应的离散化后的图像的横坐标；通过计算水平方向的旋转角度ψ，
     便可以得到某个点云的点对应离散化后的图像的纵坐标，具体计算方式为：
     θ=arcsin（z/(x2+y2+z2)-2）  ψ=arcsin(y/(x2+y2)-2)    
     每张图为camera view图中的一个channel，表达了点云不同的特征，如intensity，x坐标，半径r。
     总结：由于3D点云在做camera view投影的时候丢失了原来的3D结构信息，引入了图像中的尺度变化和遮挡两个问题，因此少有方法直接在这种模式下作3D目标检测，
     一般需要在网络输出基础上做比较多的后处理。但是camera view的表达模式，极大的增加了远处点云的上下文信息，也是一种极好的提高点云特征表达能力的方式。
七、 点对点特征（point-wise feature）提取，在自动驾驶领域，point-wise特征不会直接用来做3D目标检测任务。（pointnet、pointpillar）
     总结：目前基于point-wise feature的目标检测方法还处于研究阶段，效率无法保证，精度还未在真实自动驾驶车上测试，但由于该方法直接从点云提取特征，
     极大的保留了点云的原始信息，比较有潜力得到更好的效果。
